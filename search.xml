<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Redis</title>
      <link href="/ppy.github.io/2020/05/24/redis/"/>
      <url>/ppy.github.io/2020/05/24/redis/</url>
      
        <content type="html"><![CDATA[<h2 id="Redis-工作原理"><a href="#Redis-工作原理" class="headerlink" title="Redis 工作原理"></a>Redis 工作原理</h2><p><img src="/ppy.github.io/2020/05/24/redis/84f683e2.png" alt></p><h3 id="多路复用"><a href="#多路复用" class="headerlink" title="多路复用"></a>多路复用</h3><p>Redis 在处理客户端请求时采用 IO 多路复用，多路复用只是告诉你，那几个客户端有新消息需要去处理</p><h3 id="Redis-的单线程"><a href="#Redis-的单线程" class="headerlink" title="Redis 的单线程"></a>Redis 的单线程</h3><p>Redis 内有一个处理计算等请求的工作线程，保证所有操作是单线程在进行从而保证了 Redis 的高并发能力。<br>Redis 是基于内存的一个框架，CPU 不会成为 Redis 的瓶颈，Redis 的瓶颈是带宽、内存。</p><h3 id="IO-多线程"><a href="#IO-多线程" class="headerlink" title="IO 多线程"></a>IO 多线程</h3><p><img src="/ppy.github.io/2020/05/24/redis/9ba8f8cf.png" alt><br>Redis6.X 以后提供 IO 多线程操作模式，并非默认，需要开启配置。<br>在一步 Redis 操作中分为，IO 读取 -&gt; 计算 -&gt; 写回 IO。<br>为了充分利用 CPU，Redis 将 IO 操作改为多线程。 多线程去读取 IO，读取到后交给工作线程，工作线程处理完后交给多线程 IO。</p><h2 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h2><p>String、List、Hash、Set、Sorted Set(ZSet)</p><h2 id="Redis-缓存穿透"><a href="#Redis-缓存穿透" class="headerlink" title="Redis 缓存穿透"></a>Redis 缓存穿透</h2><p>场景：Redis 作为一款常用的缓存框架，常用于缓存数据库查询结果，将大量请求在缓存层返回。<br>因为数据库能承担的读 qps 是有限的，不做缓存导致大量请求打在数据库中，一旦将数据库打挂，那么整个服务将变为不可用状态。<br>所以有些人，会搞出你数据库不存在的 id 去调用你的接口，那么你发现 redis 没有，到数据库查询，这就叫穿透，穿两层。当请求量级较大，<br>导致数据库承不了最终挂掉。</p><p>解决方案:</p><ol><li><strong>缓存 null 值</strong>。<br>比如说，数据库常见 id 自增，都从从 1 开始，有人就会搞个 -1 作为 id 伪造请求访问你。这时，可以将 null 值保存到 redis 中。<br>优点:防止某个用户反复用同一个 ID 暴力请求。<br>缺点 :<ol><li>如果这个人，伪造随机值甚至说用 uuid，还是会击穿你。</li><li>导致大量无用数据打进 redis，redis 本身有淘汰策略，会把有用的缓存挤掉。</li></ol></li><li><strong>布隆过滤器</strong><br><code>布隆算法说数据存在，他可能不存在。 说数据不存在，他可能存在！（宁可错杀三千，不可放过一个）</code><br><img src="/ppy.github.io/2020/05/24/redis/5e9eb999.png" alt><br>底层是一个 bit 数组，key 通过 hash 将某下标置为 1 来表示它存在。 bit 数组占用内存很小的，一百亿才占用 1g 内存。<br> 布隆过滤器是<code>通过一定错误率来换取时间</code> ，<code>hash碰撞会导致一定错误率</code>。<br> 有两种方式减少错误率： 1. <code>加大数组的个数</code> 2. <code>增加Hash函数个数</code><br> <img src="/ppy.github.io/2020/05/24/redis/21fa7455.png" alt><br>对同一个 key，用三种不同 Hash 函数去 Hash，放到数组中占三个位置，三个 Hash 值都发生碰撞的概率就降低了。<br> 缺点： 占用空间，比如数组大小一共 10，用了 10 个 Hash 函数，那就直接占满了 10 个数组，这时候错误率就 100%，好在 bit 占用内存不大<br>弊端：删除数据，同一个下标可能标识多个 Hash 过来的结果，不可轻易变为 0.</li></ol><h2 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h2><p>缓存层缓存的数据，在某一时刻突然大批量失效（无法访问），导致大量请求打向数据库<br>缓存雪崩的原因：</p><ol><li>redis 中缓存的数据有效期一致导致的<br>给每条数据加上随机有效期，不要让他们失效时间一致。<code>不要突然同时失效</code></li><li>redis 挂掉了</li></ol><p>分布式缓存 :</p><ol><li>切片集群模式：数据分成小片分布在各个集群</li><li>副本集群模式：每个集群完整存放一份，放的全量数据</li></ol><h2 id="Redis-集群"><a href="#Redis-集群" class="headerlink" title="Redis 集群"></a>Redis 集群</h2><h3 id="集群的-Hash-一致性算法"><a href="#集群的-Hash-一致性算法" class="headerlink" title="集群的 Hash 一致性算法"></a>集群的 Hash 一致性算法</h3><p><img src="/ppy.github.io/2020/05/24/redis/fccf1b32.png" alt><br>redis 存放数据时，对 key 进行 Hash 后取模，到某台集群上。<br>比如说有两台，那么就是 Hash(key) % 2, 问题来了, 现在扩容新增了一台，集群数量变为 3，之前的数据怎么办？重新拿出来重新取模吗？<br>Redis 的 Hash 一致性算法就是用来解决这个问题的。<br><img src="/ppy.github.io/2020/05/24/redis/0c7dfe74.png" alt><br>一个 2 的 32 次方的 Hash 环，</p><ol><li>Redis 加入环：Hash(ip) % 2^32 到环中位置，</li><li>key 加入环：Hash(key) % 2^32 到环中位置，</li></ol><p>环中 key 按顺时针加入到 Redis 中。<br><img src="/ppy.github.io/2020/05/24/redis/563c7eff.png" alt><br>当集群发生改变时，只会影响环中两个 Redis 的数据变更。</p><p>弊端：Hash 倾斜问题，俩个 Redis 在环中距离较近，就会导致某 Redis 存储大量数据，而另一个只存储少部分。<br>解决方式：</p><h4 id="虚拟节点"><a href="#虚拟节点" class="headerlink" title="虚拟节点"></a>虚拟节点</h4><p><img src="/ppy.github.io/2020/05/24/redis/8e459f6a.png" alt><br>右侧 redis1 redis2 为真是节点，左侧为映射节点，这样就解决了 Hash 倾斜问题。 如果加入虚拟节点还是不均衡，那就继续添加虚拟节点</p><h2 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h2><p><code>缓存击穿和缓存雪崩的本质都是缓存穿透，是缓存穿透的特殊表现</code><br><code>一条</code>热门数据，在缓存失效，瞬间大量请求打入数据库。</p><p>解决方式：</p><ol><li><p>分布式锁<br>同事见 1w 个请求过来，当发现缓存没数据后，去争夺分<br>布式锁，拿到锁的去库中查询，然后放入缓存，那么剩余的 9999 可在缓存中取到数据。<br><code>这种方式效率低，导致大量请求卡在cpu瞬间升高</code></p></li><li><p>不加分布式锁，从库中请求出来后直接放入缓存<br>一般公司不会采用方案 1，因为量不会怎么大。<br>一般来说 一瞬间 100 个并发同一个 key 已经算是很高的了。<br>所以 100 个请求直接是从库中取，然后放入缓存，那么 第 101 个请求就可以从缓存中读取了。</p></li></ol><h2 id="Redis-分布式锁与-Zookeeper-分布式锁的区别"><a href="#Redis-分布式锁与-Zookeeper-分布式锁的区别" class="headerlink" title="Redis 分布式锁与 Zookeeper 分布式锁的区别"></a>Redis 分布式锁与 Zookeeper 分布式锁的区别</h2><p><img src="/ppy.github.io/2020/05/24/redis/87fd9ce7.png" alt><br>zookeeper 有子节点概念，三个 client 同时 lock 创建节点，会顺序排列。<br>没排在 01 上的节点会注册监听事件，监听上一个节点被删除事件，当上一个节点做完了业务后删掉节点，后续节点则依次进行业务。</p><h2 id="持久化"><a href="#持久化" class="headerlink" title="持久化"></a>持久化</h2><h3 id="AOF"><a href="#AOF" class="headerlink" title="AOF"></a>AOF</h3><h3 id="RDB"><a href="#RDB" class="headerlink" title="RDB"></a>RDB</h3>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HashMap</title>
      <link href="/ppy.github.io/2020/05/24/HashMap/"/>
      <url>/ppy.github.io/2020/05/24/HashMap/</url>
      
        <content type="html"><![CDATA[<h2 id="HashMap"><a href="#HashMap" class="headerlink" title="HashMap"></a>HashMap</h2><p>hashMap 底层数据结构：<code>数组</code><br><code>map.put(&quot;张三&quot;,xx)</code><br>对 key 计算得到 hash，然后对 hash 值进行取模，定位到数组中的某下标中去。<br> [&lt;张三，测试数据&gt;，&lt;李四，测试数据&gt;]</p><h3 id="HashMap-怎么进行优化的"><a href="#HashMap-怎么进行优化的" class="headerlink" title="HashMap 怎么进行优化的"></a>HashMap 怎么进行优化的</h3><h4 id="寻址算法优化"><a href="#寻址算法优化" class="headerlink" title="寻址算法优化"></a>寻址算法优化</h4><p>数据在插入前，进行一个 hash 计算。<br>高位右移 16 位，与原数进行异或计算,目的为了保留高位与低位的特征，减少 hash 冲突。<br>再与数组长度 n - 1 进行与运算，例如 16,16 转换为二进制 高位全为 0，与其进行与运算，高位部分的运算可忽略。</p><pre class=" language-Java"><code class="language-Java">static final int hash(Object key) {        int h;        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);    }</code></pre><p>步骤：</p><hr><ol><li><p>取到 key 的 hash 值，32 位二进制数<br><code>1111 1111 1111 1111 1111 1010 0111 1100</code></p></li><li><p>右移 16 位，高位 0 补齐<br><code>0000 0000 0000 00001111 1111 1111 1111</code></p></li><li><p>异或运算，同位数字相同得到 0，不同则<br>1111 1111 1111 1111 1111 1010 0111 1100<br>0000 0000 0000 0000 1111 1111 1111 1111<br>得:1111 1111 1111 1111 0000 0101 1000 0011</p></li><li><p>最后转换 int 值(int 值本身也是 32 位)</p></li><li><p>取到 map 的长度 - 1 转换 2 进制 和 上面的值做与运算</p></li></ol><p>比如 16 长度的 map 16 - 1<br> 0000 0000 0000 0000 0000 0000 0000 1111<br> 1111 1111 1111 1111 0000 0101 1000 0011</p><p>这样做的目的是 ，16 做完了二进制 高位全是 0<br> 而 map 的长度不会很大最多是后 16 位有值，<br>这样一来，高位基本不做运算。</p><p>而第一步做的异或运算是为了在这一步。因为这里与运算基本是后 16 位在做运算<br>很有可能后 16 位的值一样导致 hash 冲突。<br>所以高 16 位与低 16 位做异或可以同时保留 高位与低位的特征，减少 hash 冲突。`</p><hr><h4 id="hash-冲突如何解决"><a href="#hash-冲突如何解决" class="headerlink" title="hash 冲突如何解决"></a>hash 冲突如何解决</h4><p>1.7 之前为数组+链表<br>1.8 以后 hashMap 处理冲突有两种方式，链表 O(n)与红黑树 O(log n)。<br><img src="/ppy.github.io/2020/05/24/HashMap/13de3a30.png" alt><br>当 hash 运算时，会存在俩个或两个以上元素取模到同一数组下标中去。<br>最开始会采用链表的形式将多个元素挂在到同一下标，当链表长度达到一定量（大于 8），会转换为红黑树。<br>为什么要转换红黑树？<br>当 map 在 get 元素时，发现是链表，这时需要遍历链表去取出元素，最坏情况下时间复杂度为 O(n)<br>而红黑树遍历找元素的复杂度为 O(log n)</p><h3 id="HashMap-的扩容"><a href="#HashMap-的扩容" class="headerlink" title="HashMap 的扩容"></a>HashMap 的扩容</h3><p>初始值:16<br>扩容因子:0.75<br>初始数组大小为 16,当数组元素达到<code>数组长度*0.75</code>时，扩容两倍。</p><hr><p>判断二进制结果中是否多出一个 bit 的 1， 如果没有多 ，那么就是原来的 index<br>如果多了，就是 index+oldcap，通过这个方式，避免了 rehash 的时候用每个 hash 对新数组取保，取模性能不高，位运算性能比较高</p><p>比如</p><p><img src="/ppy.github.io/2020/05/24/HashMap/f2aeb9d3.png" alt></p><p>1111 = 15<br>11111 = 31<br>如果长度发生变化，则 index 与 长度 进行 或 运算，得到新位置下标</p><h4 id="设定初始值容量"><a href="#设定初始值容量" class="headerlink" title="设定初始值容量"></a>设定初始值容量</h4><p>new HashMap()，如果传入初始值 k，则初始化大小为 <code>大于k的2的整次方</code>，例如传 10，大小为 16</p><pre class=" language-Java"><code class="language-Java">static final int tableSizeFor(int cap) {  int n = cap - 1;  n |= n >>> 1;  n |= n >>> 2;  n |= n >>> 4;  n |= n >>> 8;  n |= n >>> 16;  return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;}</code></pre><h2 id="ConcurrentHashMap"><a href="#ConcurrentHashMap" class="headerlink" title="ConcurrentHashMap"></a>ConcurrentHashMap</h2><p>1.8 以前 多个数组，分段加锁，一个数组一个锁，<br>1.8 以后 优化细粒度，一个数组，每个元素进行 cas，如果失败了说明有人，此时 synchronized 对数组元素加锁，链表+红黑树处理，对数组的每个元素 cas 加锁，</p><p>hashMap 底层是一个大数组</p><p>1.7 及以前 分段<br>[数组 1][数组2] [数组 3] 每个数组对应一个锁</p><p>多个线程过来 线程 1 对数组 1[5] 线程 2 对数组 2[25]，加的不是同一把锁</p><p>1.8 以后，锁粒度细化，[一个大数组]，每个元素进行 put 都是一个不同的锁，采用 CAS 策略。</p><p>比如俩个人同时对[5] put，这时失败了，就需要在这个位置基于链表+红黑树进行处理，加 synchronized 对数组[5],基于红黑树或者是链表在这个位置插进去自己的数据（为什么要用链表加红黑树，和 hashMap 的 hash 碰撞有关，当发生 hash 碰撞，会把元素插在同一数组上，用链表的形式，链表达到一定程度就会变为红黑树方式）</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HashMap </tag>
            
            <tag> Java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>hexo、markdown用法</title>
      <link href="/ppy.github.io/2020/05/24/markdown/"/>
      <url>/ppy.github.io/2020/05/24/markdown/</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.jianshu.com/p/8363e3815b92" target="_blank" rel="noopener">Markdown 语法中输入数学公式（MathJax）及特殊符号</a><br><a href="https://yafine-blog.cn/posts/4ab2.html" target="_blank" rel="noopener">Hexo+github 搭建博客(超级详细版，精细入微)</a></p>]]></content>
      
      
      <categories>
          
          <category> markdown </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Markdown </tag>
            
            <tag> Hexo </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>算法</title>
      <link href="/ppy.github.io/2020/05/24/algorithm/"/>
      <url>/ppy.github.io/2020/05/24/algorithm/</url>
      
        <content type="html"><![CDATA[<h2 id="数组展平"><a href="#数组展平" class="headerlink" title="数组展平"></a>数组展平</h2><h3 id="二维数组展平"><a href="#二维数组展平" class="headerlink" title="二维数组展平"></a>二维数组展平</h3><p>展平一个数组，数组最多二维[[1,2],[3,4]] =&gt; [1,2,3,4]</p><pre class=" language-Javascript"><code class="language-Javascript">function flatten(arr){  return [].concat(...arr)}let arr = [[1,2],[3,4]][].concat(arr)[].concat(...[arr])[].apply(null,[arr])</code></pre><p>concat() 方法用于连接两个或多个数组。<br>该方法不会改变现有的数组，而仅仅会返回被连接数组的一个副本。</p><h3 id="多维数组展平-递归"><a href="#多维数组展平-递归" class="headerlink" title="多维数组展平(递归)"></a>多维数组展平(递归)</h3><p>展评一个数组,[[1,2],3,[[[4],5]]] =&gt; [1,2,3,4,5]<br>对数组 ${S}$ = {${a}_1$,${a}_2$,…,${a}_n$},函数${F}$将数组展平<br>${F}({S}) = {F}(a_1)\cup{F}(a_2)\cup…\cup{F}(a_n)$<br>$<br>  F(a_i)=<br>  \begin{cases}<br>  a_i数字 \<br>  F(a_i) 数组<br>  \end{cases}<br>$</p><pre class=" language-Javascript"><code class="language-Javascript">function flatten(arr) {  return [].concat(...arr.map((x) => (Array.isArray(x) ? flatten(x) : x)));}</code></pre><h2 id="函数"><a href="#函数" class="headerlink" title="函数"></a>函数</h2><h3 id="函数节流"><a href="#函数节流" class="headerlink" title="函数节流"></a>函数节流</h3><p>添加滚动事件 60ms 响应 1 次</p><pre class=" language-Javascript"><code class="language-Javascript">document.addEventListener('scroll', throttle(console.log));function throttle(func, delay = 60) {  let lock = false;  return (...args) => {    if (lock) {      return;    }    func(...args);    lock = true;    setTimeout(() => {      lock = false;    }, delay);  };}</code></pre><p>过滤掉重复的验证事件(用户输入停止后 300ms 触发验证)</p><pre class=" language-Javascript"><code class="language-Javascript">function throttle(func, delay = 300, I = null) {  return (...args) => {    clearInterval(I);    I = setTimeout(func.bind(null, ...args), delay);    // I = setTimeout((...args) => {func(...args)}, delay);  };}</code></pre><h2 id="柯里化"><a href="#柯里化" class="headerlink" title="柯里化"></a>柯里化</h2><p>柯里化，英语：Currying(果然是满满的英译中的既视感)，是把接受多个参数的函数变换成接受一个单一参数（最初函数的第一个参数）的函数，并且返回接受余下的参数而且返回结果的新函数的技术。</p><p><a href="https://www.jianshu.com/p/2975c25e4d71" target="_blank" rel="noopener">详解 JS 函数柯里化</a></p><pre class=" language-Javascript"><code class="language-Javascript">const curry = (func) => {  const g = (...allArgs) =>    allArgs.length >= func.length      ? func(...allArgs)      : (...args) => g(...allArgs, ...args);  return g;};const foo = curry((a, b, c, d) => {  console.log(a, b, c, d);});</code></pre><p>对于 curry(foo),g 函数参数足够 4 个,就调用 foo(a,b,c,d),如果小于 4 个就返回一个可以继续积累参数的函数</p><h3 id="Y-组合子"><a href="#Y-组合子" class="headerlink" title="Y-组合子"></a>Y-组合子</h3><p>前置知识 lamabda 演算</p><pre class=" language-Javascript"><code class="language-Javascript">const y = (function (le) {  return function (f) {    return f(f);  };})(function (f) {  return le(function (...x) {    return f(f)(...x);  });});const curryY = (func) =>  y((g) => {    (...allArgs) => {      allArgs.length >= func.length        ? func(...allArgs)        : (...args) => g(...allArgs, ...args);    };  });const foo = curryY((a, b, c, d) => {  console.log(a, b, c, d);});foo(1)(2)(3)(4);</code></pre>]]></content>
      
      
      <categories>
          
          <category> Javascript </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Javascript </tag>
            
            <tag> Javascript算法 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
